{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f083703",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "# ==== CONFIGURATION ====\n",
    "INPUT_ROOT = r\"E:\\dev\\thesis-testing\\common-voices-mozilla\\cv-valid-train\\cv-valid-train\"\n",
    "OUTPUT_DIR = r\"E:\\dev\\thesis-testing\\common-voices-mozilla\\cv-valid-train\\cv-valid-train-wav\"   # Where to move all WAV files\n",
    "FILE_EXTENSION = \"wav\"  # File extension to look for\n",
    "\n",
    "def find_audio_files(root_dir, extension):\n",
    "    \"\"\"Recursively find all files with the given extension under root_dir.\"\"\"\n",
    "    return list(Path(root_dir).rglob(f'*.{extension}'))\n",
    "\n",
    "def move_file(file_info):\n",
    "    \"\"\"Move a single file to the output directory with a unique name.\"\"\"\n",
    "    src_path, output_dir = file_info\n",
    "    # Create a unique name using parent folder names to avoid collisions\n",
    "    unique_name = f\"{src_path.parent.name}_{src_path.name}\"\n",
    "    dest_path = Path(output_dir) / unique_name\n",
    "    \n",
    "    try:\n",
    "        shutil.move(str(src_path), str(dest_path))\n",
    "        return f\"✓ Moved: {src_path.name}\"\n",
    "    except Exception as e:\n",
    "        return f\"✗ Error moving {src_path.name}: {e}\"\n",
    "\n",
    "def move_all_wav_files():\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path = Path(OUTPUT_DIR)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Find all WAV files\n",
    "    wav_files = find_audio_files(INPUT_ROOT, FILE_EXTENSION)\n",
    "    \n",
    "    if not wav_files:\n",
    "        print(f\"No {FILE_EXTENSION.upper()} files found in {INPUT_ROOT}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(wav_files)} {FILE_EXTENSION.upper()} files to move\")\n",
    "\n",
    "    # Prepare file info for processing\n",
    "    file_info_list = [(f, OUTPUT_DIR) for f in wav_files]\n",
    "\n",
    "    max_workers = min(16, len(file_info_list))\n",
    "    successful_moves = 0\n",
    "    failed_moves = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Use ThreadPoolExecutor for parallel file operations\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_file = {executor.submit(move_file, file_info): file_info \n",
    "                         for file_info in file_info_list}\n",
    "        \n",
    "        with tqdm(total=len(file_info_list), desc=\"Moving files\", unit=\"file\", ncols=80) as pbar:\n",
    "            for future in as_completed(future_to_file):\n",
    "                result = future.result()\n",
    "                if result.startswith(\"✓\"):\n",
    "                    successful_moves += 1\n",
    "                else:\n",
    "                    failed_moves += 1\n",
    "                    print(f\"\\n{result}\")\n",
    "                pbar.update(1)\n",
    "\n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"FILE MOVING SUMMARY\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Total files processed: {len(wav_files)}\")\n",
    "    print(f\"Successfully moved: {successful_moves}\")\n",
    "    print(f\"Failed to move: {failed_moves}\")\n",
    "    print(f\"Total processing time: {processing_time:.2f} seconds\")\n",
    "\n",
    "    if successful_moves > 0:\n",
    "        avg_time = processing_time / len(wav_files) if len(wav_files) > 0 else 0\n",
    "        print(f\"Average time per file: {avg_time:.4f} seconds\")\n",
    "        print(f\"\\nAll files moved to: {output_path.absolute()}\")\n",
    "\n",
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    move_all_wav_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045934e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import os\n",
    "\n",
    "# ==== CONFIGURATION ====\n",
    "INPUT_TYPE = \"mp3\"  # File extension to search for, e.g., \"flac\", \"mp3\"\n",
    "INPUT_FORMAT = \"mp3\"  # Format for pydub, usually same as INPUT_TYPE\n",
    "INPUT_ROOT = r\"E:\\dev\\thesis-testing\\common-voices-mozilla\\cv-valid-train\\cv-valid-train\"\n",
    "OUTPUT_ROOT = r\"E:\\dev\\thesis-testing\\common-voices-mozilla\\cv-valid-train\\cv-valid-train-wav2\"   # Where to move all WAV files\n",
    "\n",
    "def find_audio_files(root_dir, extension):\n",
    "    \"\"\"Recursively find all files with the given extension under root_dir.\"\"\"\n",
    "    return list(Path(root_dir).rglob(f'*.{extension}'))\n",
    "\n",
    "def get_output_path(input_file, input_root, output_root):\n",
    "    \"\"\"Return the output WAV path, mirroring the input directory structure.\"\"\"\n",
    "    relative_path = input_file.relative_to(input_root)\n",
    "    return Path(output_root) / relative_path.with_suffix('.wav')\n",
    "\n",
    "def convert_audio_file(file_info):\n",
    "    \"\"\"Convert a single audio file to WAV.\"\"\"\n",
    "    file_path, output_file = file_info\n",
    "    thread_id = threading.current_thread().ident\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(file_path, format=INPUT_FORMAT)\n",
    "        output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        audio.export(output_file, format=\"wav\")\n",
    "        return f\"✓ Thread {thread_id}: {file_path.name}\"\n",
    "    except Exception as e:\n",
    "        return f\"✗ Thread {thread_id}: Error processing {file_path.name}: {e}\"\n",
    "\n",
    "def optimize_audio_conversion():\n",
    "    input_path = Path(INPUT_ROOT)\n",
    "    output_path = Path(OUTPUT_ROOT)\n",
    "\n",
    "    # Find all matching files recursively\n",
    "    input_files = find_audio_files(input_path, INPUT_TYPE)\n",
    "\n",
    "    if not input_files:\n",
    "        print(f\"No {INPUT_TYPE.upper()} files found in {input_path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(input_files)} {INPUT_TYPE.upper()} files to process\")\n",
    "\n",
    "    file_info_list = []\n",
    "    for input_file in input_files:\n",
    "        out_file = get_output_path(input_file, input_path, output_path)\n",
    "        if out_file.exists():\n",
    "            print(f\"Skipping {input_file} - WAV file already exists\")\n",
    "            continue\n",
    "        file_info_list.append((input_file, out_file))\n",
    "\n",
    "    if not file_info_list:\n",
    "        print(\"All files have already been converted.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Processing {len(file_info_list)} files...\")\n",
    "\n",
    "    max_workers = min(16, len(file_info_list))\n",
    "    successful_conversions = 0\n",
    "    failed_conversions = 0\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        future_to_file = {executor.submit(convert_audio_file, file_info): file_info for file_info in file_info_list}\n",
    "        with tqdm(total=len(file_info_list), desc=\"Converting files\", unit=\"file\", ncols=80) as pbar:\n",
    "            for future in as_completed(future_to_file):\n",
    "                result = future.result()\n",
    "                if result.startswith(\"✓\"):\n",
    "                    successful_conversions += 1\n",
    "                else:\n",
    "                    failed_conversions += 1\n",
    "                    print(f\"\\n{result}\")\n",
    "                pbar.update(1)\n",
    "\n",
    "    end_time = time.time()\n",
    "    processing_time = end_time - start_time\n",
    "\n",
    "    # Summary\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"CONVERSION SUMMARY\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Total files processed: {len(file_info_list)}\")\n",
    "    print(f\"Successful conversions: {successful_conversions}\")\n",
    "    print(f\"Failed conversions: {failed_conversions}\")\n",
    "    print(f\"Total processing time: {processing_time:.2f} seconds\")\n",
    "\n",
    "    if successful_conversions > 0:\n",
    "        avg_time = processing_time / len(file_info_list)\n",
    "        print(f\"Average time per file: {avg_time:.2f} seconds\")\n",
    "\n",
    "# Run the optimization\n",
    "if __name__ == \"__main__\":\n",
    "    optimize_audio_conversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37042bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "def get_file_hash(file_path, block_size=65536):\n",
    "    \"\"\"Generate MD5 hash for a file\"\"\"\n",
    "    hasher = hashlib.md5()\n",
    "    with open(file_path, 'rb') as f:\n",
    "        buf = f.read(block_size)\n",
    "        while len(buf) > 0:\n",
    "            hasher.update(buf)\n",
    "            buf = f.read(block_size)\n",
    "    return file_path, hasher.hexdigest()\n",
    "\n",
    "def process_batch(files, max_workers=8):\n",
    "    \"\"\"Process a batch of files in parallel\"\"\"\n",
    "    results = {}\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all tasks\n",
    "        future_to_file = {executor.submit(get_file_hash, file): file for file in files}\n",
    "        \n",
    "        # Process completed tasks as they finish\n",
    "        for future in tqdm(as_completed(future_to_file), total=len(files), desc=\"Processing files\"):\n",
    "            try:\n",
    "                file_path, file_hash = future.result()\n",
    "                results[file_path] = file_hash\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {future_to_file[future]}: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def find_duplicates(directory, max_workers=8):\n",
    "    \"\"\"Find duplicate files in the given directory using multithreading\"\"\"\n",
    "    directory = Path(directory)\n",
    "    hashes = defaultdict(list)\n",
    "    \n",
    "    # Get all WAV files recursively\n",
    "    files = list(directory.rglob('*.wav'))\n",
    "    \n",
    "    # Process files in parallel\n",
    "    results = process_batch(files, max_workers)\n",
    "    \n",
    "    # Group files by their hashes\n",
    "    for file_path, file_hash in results.items():\n",
    "        hashes[file_hash].append(str(file_path))\n",
    "    \n",
    "    # Filter out unique files\n",
    "    duplicates = {k: v for k, v in hashes.items() if len(v) > 1}\n",
    "    return duplicates\n",
    "\n",
    "# Usage\n",
    "directory_path = r\"E:\\dev\\thesis-testing\\dataset-balanced\\val\\real\"\n",
    "duplicates = find_duplicates(directory_path, max_workers=(os.cpu_count() * 5))  # Adjust max_workers based on your CPU\n",
    "\n",
    "# Print results\n",
    "if duplicates:\n",
    "    print(f\"Found {len(duplicates)} sets of duplicate files:\")\n",
    "    for i, (hash_val, files) in enumerate(duplicates.items(), 1):\n",
    "        print(f\"\\nDuplicate set {i} (hash: {hash_val}):\")\n",
    "        for file in files:\n",
    "            print(f\"  - {file}\")\n",
    "else:\n",
    "    print(\"No duplicate files found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
